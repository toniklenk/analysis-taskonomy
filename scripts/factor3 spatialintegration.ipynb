{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import os, pickle\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "# stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# neural networks\n",
    "import torch, torch.utils.model_zoo  # required to load nets\n",
    "from torchvision.models.feature_extraction import (\n",
    "    get_graph_node_names,\n",
    "    create_feature_extractor,\n",
    ")\n",
    "\n",
    "# thesis library\n",
    "from lib.functions_scripting import *\n",
    "from lib.functions_base_analysis import *\n",
    "from lib.functions_second_analysis import *\n",
    "from lib.ImageDataset import ImageDataset\n",
    "from lib.NetworkScorer import NetworkScorer\n",
    "from lib.PatternGenerator import Pattern_Generator\n",
    "from lib.ActivationPattern import Activation_Pattern\n",
    "from lib.transforms import VisualPriorRepresentation\n",
    "from lib.PatternGeneratorSearchlight import PatternGeneratorSearchlight\n",
    "\n",
    "\n",
    "def study2behaviour(st):\n",
    "    return BEHAVIOUR_NAMES[STUDY_NAMES.index(st)]\n",
    "\n",
    "\n",
    "def study2dataset(st):\n",
    "    if st in STUDY_NAMES[:2]:\n",
    "        return DATASET_NAMES[0]\n",
    "    if st == STUDY_NAMES[2]:\n",
    "        return DATASET_NAMES[1]\n",
    "    if st == STUDY_NAMES[3]:\n",
    "        return DATASET_NAMES[2]\n",
    "\n",
    "\n",
    "# storing a NetworkScorer object for saving backprojected scores\n",
    "# TODO needs to be adapted when analysing multiple nets\n",
    "BACKPROJECTED_SCORES_FOLDER = \"./backprojected_scores\"\n",
    "\n",
    "PATH_SING_NET_RDMS = os.path.join(PATH_RESULTS, \"spatial integration\", \"single network rdms\")\n",
    "PATH_SUBSETDATA = os.path.join(PATH_RESULTS, \"spatial integration\", \"subsetdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_models = MODEL_NAMES\n",
    "_studies = STUDY_NAMES\n",
    "_datasets = DATASET_NAMES\n",
    "_scales = SCALE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do for each studys:\n",
    "\n",
    "1. For every network: RDM (imageXimage) of searchlight integration scoring. Best ibcorr-performing layer in study.\n",
    "\n",
    "3. netXnet RDM of RDMs from (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ibcorr_for_spatialanalysis(mo, sc):\n",
    "    \"\"\" load ibcorr for one net\"\"\"\n",
    "    l = []\n",
    "    for st in STUDY_NAMES:\n",
    "        d = pd.read_csv(os.path.join(PATH_IB_CORRELATIONS, mo, st, sc, 'ib_correlations.csv'), header=None)\n",
    "        d.insert(0, 'study', st)\n",
    "        d = d.reset_index().rename(columns={\"index\":\"layer\", 0:\"ibcorr\"})\n",
    "        l.append(d)\n",
    "    return pd.concat(l).reset_index(drop=True)\n",
    "\n",
    "#setup nets for extracting activations from best layer\n",
    "def setup_singlelayer(model_name: str, layer_idx: int):\n",
    "    \"\"\" Setup activation extractor for a single layer of a tasnomomy network\n",
    "    \"\"\"\n",
    "    VisualPriorRepresentation._load_unloaded_nets([model_name])\n",
    "    net = VisualPriorRepresentation.feature_task_to_net[model_name]\n",
    "\n",
    "    _, eval_nodes = get_graph_node_names(net)\n",
    "    return_nodes = {node:node for node in eval_nodes if \"conv\" in node or 'fc' in node}\n",
    "    \n",
    "    layer_name = list(return_nodes.keys())[layer_idx]\n",
    "    return create_feature_extractor(net, return_nodes={layer_name:layer_name}), layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_spatialintegration_analysis_bestlayer(mo, st, sc):\n",
    "    # setup best-layer activation extractor\n",
    "    df_ibcorr = load_ibcorr_for_spatialanalysis(mo, sc)\n",
    "    best_ibcorr = (df_ibcorr\n",
    "                   .iloc[df_ibcorr.groupby('study').ibcorr.idxmax(),:]\n",
    "                   .set_index('study'))\n",
    "    idx = best_ibcorr.loc[st].layer.astype(int)\n",
    "    activation_extractor, layername = setup_singlelayer(mo, idx)\n",
    "\n",
    "    # setup Pattern Generator\n",
    "    dataset = ImageDataset(os.path.join(PATH_IMAGES, study2dataset(st), sc))\n",
    "    dummy_image = next(iter(dataset))\n",
    "    net_activation = activation_extractor(dummy_image[0])\n",
    "    activation_shape = taskonomy_activation_layer_shapes(net_activation)\n",
    "    activation_shape = torch.Size(d for d in activation_shape[layername] if d != 1)\n",
    "    pat = PatternGeneratorSearchlight(activation_shape, layername)\n",
    "    \n",
    "    # setup storing results\n",
    "    # layer x image x subset\n",
    "    num_layers = 1\n",
    "    num_images = dataset.img_count\n",
    "    num_subsets = pat.num_subsets\n",
    "    integration = np.full([num_layers,num_images,num_subsets], np.nan, dtype=np.float64)\n",
    "\n",
    "    # run analysis\n",
    "    #cnt = 0\n",
    "    for img_id, (img_full, img_v1, img_v2) in enumerate(iter(dataset)):\n",
    "        #if cnt % 30 == 0: print(cnt, end= ' ')\n",
    "        #cnt=cnt+1\n",
    "        \n",
    "        # activations as tensors\n",
    "        act_full = activation_extractor(img_full)[layername].squeeze()\n",
    "        act_v1 = activation_extractor(img_v1)[layername].squeeze()\n",
    "        act_v2 = activation_extractor(img_v2)[layername].squeeze()\n",
    "        act_avg = (act_v1 + act_v2) / 2.\n",
    "\n",
    "        # iterate 3D positions\n",
    "        pat_it = iter(pat)\n",
    "        for subset_num, roi_mask in pat_it:\n",
    "            \n",
    "            subset_act_full = act_full[roi_mask]\n",
    "            subset_act_avg = act_avg[roi_mask]\n",
    "\n",
    "            # calculate integration and store it\n",
    "            subset_integration = pearsonr(subset_act_full.flatten(), subset_act_avg.flatten())[0]\n",
    "            integration[:,img_id, subset_num] = subset_integration\n",
    "\n",
    "    return integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = 'depth_euclidean'\n",
    "st = STUDY_NAMES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_ibcorr(mo, sc = SCALE_NAME):\n",
    "    \"\"\" load ibcorr for one net\"\"\"\n",
    "    l = []\n",
    "    for st in STUDY_NAMES:\n",
    "        d = pd.read_csv(os.path.join(PATH_IB_CORRELATIONS, mo, st, sc, 'ib_correlations.csv'), header=None)\n",
    "        d.insert(0, 'study', st)\n",
    "        d = d.reset_index().rename(columns={\"index\":\"layer\", 0:\"ibcorr\"})\n",
    "        l.append(d)\n",
    "    return pd.concat(l).reset_index(drop=True)\n",
    "\n",
    "df_ibcorr = load_ibcorr(mo)\n",
    "df_ibcorr\n",
    "\n",
    "# visualize this: add lineplot for ibcorr of 4 studies for per net\n",
    "best_ibcorr = df_ibcorr.iloc[df_ibcorr.groupby('study').ibcorr.idxmax(),:].set_index('study')\n",
    "best_ibcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup nets for extracting activations from best layer\n",
    "def setup_singlelayer(model_name: str, layer_idx: int):\n",
    "    \"\"\" Setup activation extractor for a single layer of a tasnomomy network\n",
    "    \"\"\"\n",
    "    VisualPriorRepresentation._load_unloaded_nets([model_name])\n",
    "    net = VisualPriorRepresentation.feature_task_to_net[model_name]\n",
    "\n",
    "    _, eval_nodes = get_graph_node_names(net)\n",
    "    return_nodes = {node:node for node in eval_nodes if \"conv\" in node or 'fc' in node}\n",
    "    \n",
    "    layer_name = list(return_nodes.keys())[layer_idx]\n",
    "    return create_feature_extractor(net, return_nodes={layer_name:layer_name}), layer_name\n",
    "\n",
    "idx = best_ibcorr.loc[st].layer.astype(int)\n",
    "activation_extractor, layername = setup_singlelayer(mo, idx)\n",
    "layername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load net and activation shape (of best layer)\n",
    "dataset = ImageDataset(os.path.join(PATH_IMAGES, study2dataset(st), SCALE_NAME))\n",
    "dummy_image = next(iter(dataset))\n",
    "net_activation = activation_extractor(dummy_image[0])\n",
    "activation_shape = taskonomy_activation_layer_shapes(net_activation)\n",
    "activation_shape = torch.Size(d for d in activation_shape[layername] if d != 1)\n",
    "\n",
    "pat = PatternGeneratorSearchlight(activation_shape, layername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer x image x subset\n",
    "num_layers = 1\n",
    "num_images = dataset.img_count\n",
    "num_subsets = pat.num_subsets\n",
    "integration = np.full([num_layers,num_images,num_subsets], np.nan, dtype=np.float64)\n",
    "\n",
    "# run analysis\n",
    "cnt = 0\n",
    "\n",
    "for img_id, (img_full, img_v1, img_v2) in enumerate(iter(dataset)):\n",
    "    if cnt % 30 == 0: print(cnt, end= ' ')\n",
    "    cnt=cnt+1\n",
    "    \n",
    "    # activations as tensors\n",
    "    act_full = activation_extractor(img_full)[layername].squeeze()\n",
    "    act_v1 = activation_extractor(img_v1)[layername].squeeze()\n",
    "    act_v2 = activation_extractor(img_v2)[layername].squeeze()\n",
    "    act_avg = (act_v1 + act_v2) / 2.\n",
    "\n",
    "    # iterate 3D positions in layer\n",
    "    pat_it = iter(pat)\n",
    "    for subset_num, roi_mask in pat_it:\n",
    "        \n",
    "        subset_act_full = act_full[roi_mask]\n",
    "        subset_act_avg = act_avg[roi_mask]\n",
    "\n",
    "        # calculate integration and store it\n",
    "        subset_integration = pearsonr(subset_act_full.flatten(), subset_act_avg.flatten())[0]\n",
    "        integration[:,img_id, subset_num] = subset_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_RESULTS, RESULTS_SEMANTIC_PLACES1, \"semantic_integration.npy\"), 'rb') as f:\n",
    "    integration = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beauty ratings\n",
    "beauty_ratings = pd.read_csv(os.path.join(PATH_RATINGS, study2behaviour(st)), header=None).mean(axis=1)\n",
    "\n",
    "# correlate integration with beauty\n",
    "scores = correlate_integration_beauty(integration, beauty_ratings)\n",
    "\n",
    "# convert integration back to 3D layer space\n",
    "ns = NetworkScorer({layername:activation_shape})\n",
    "ns.map_back_scores(scores, pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run analysis\n",
    "# TODO: change to save as hdf5\n",
    "_study = \"complexity order\"\n",
    "_scale = \"scale4\"\n",
    "\n",
    "\n",
    "for mo in MODEL_NAMES:\n",
    "    print(mo)\n",
    "    integration_subsets = run_spatialintegration_analysis_bestlayer(mo, _study, _scale)\n",
    "    integration = pd.DataFrame(integration_subsets.squeeze().T)\n",
    "    integration.to_csv(\n",
    "        os.path.join(\n",
    "            PATH_RESULTS,\n",
    "            \"spatial integration\",\n",
    "            _scale,\n",
    "            _study + \" subsetdata\",\n",
    "            mo + \".csv\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# with Pool() as pool:\n",
    "#     l1 = pool.starmap(run_spatialintegration_analysis_bestlayer, zip(MODEL_NAMES[5:], [\"short presentation\"] * len(MODEL_NAMES[5:]), [\"scale4\"] * len(MODEL_NAMES[5:]))   )\n",
    "\n",
    "#d1 = {k: d1[k] for k in _models}\n",
    "\n",
    "# for mo, data in l1:\n",
    "#     df = pd.DataFrame(data.squeeze().T)\n",
    "#     calculate_rdm(df)\n",
    "#     df.to_csv(os.path.join(PATH_RESULTS, \"spatial integration\", \"scale4\", \"study1\", mo + \".csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network imageXimage RDMs\n",
    "representing spatial structure in common space across networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate network RDMs from subsetdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspi_rdms = dfspi.groupby(\"model\").corr().groupby(\"model\").apply(set_diagonal_to_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network RDMs as hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network RDMs from hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspi_rdms = pd.read_hdf(\n",
    "    os.path.join(\n",
    "        PATH_RESULTS,\n",
    "        \"spatial integration\",\n",
    "        \"single network rdms\",\n",
    "        \"scale4 study1 allnets.h5\",\n",
    "    ),\n",
    "    key=\"dfspi_rdms\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfspi_rdms.to_hdf(\n",
    "#     os.path.join(\n",
    "#         PATH_RESULTS,\n",
    "#         \"spatial integration\",\n",
    "#         _scale,\n",
    "#         \"rdms \" + _study + \" allnets.h5\",\n",
    "#     ),\n",
    "#     key=\"dfspi_rdms\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictorRDM\n",
    "\n",
    "\"how\"\n",
    "\"where\" or alternatively \"what\",  which is the same because its spatial integration. Check for correlation between the what (represented by the integration ratings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = []\n",
    "for filename in os.listdir(PATH_SING_NET_RDMS):\n",
    "    scale, study, _ = Path(filename).stem.split()\n",
    "    study = studyname(study)\n",
    "    data = (\n",
    "        pd.read_hdf(os.path.join(PATH_SING_NET_RDMS, filename))\n",
    "        .assign(study=study, scale=scale)\n",
    "        .set_index([\"study\", \"scale\"], append=True)\n",
    "        .reorder_levels([\"study\", \"scale\", \"model\", \"img\"])\n",
    "    )\n",
    "    dl.append(data)\n",
    "\n",
    "dfspi_rdms = pd.concat(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <th>scale</th>\n",
       "      <th>model</th>\n",
       "      <th>img</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">complexity order</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">scale8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">autoencoding</th>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.268209</td>\n",
       "      <td>0.052688</td>\n",
       "      <td>0.319964</td>\n",
       "      <td>0.298544</td>\n",
       "      <td>0.303844</td>\n",
       "      <td>0.338253</td>\n",
       "      <td>0.080624</td>\n",
       "      <td>0.168532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162140</td>\n",
       "      <td>0.097780</td>\n",
       "      <td>0.153127</td>\n",
       "      <td>0.393909</td>\n",
       "      <td>0.127255</td>\n",
       "      <td>0.232155</td>\n",
       "      <td>0.314069</td>\n",
       "      <td>0.187343</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.086527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>0.468951</td>\n",
       "      <td>0.187701</td>\n",
       "      <td>0.216722</td>\n",
       "      <td>0.145107</td>\n",
       "      <td>0.207201</td>\n",
       "      <td>0.228692</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056059</td>\n",
       "      <td>0.169147</td>\n",
       "      <td>0.402768</td>\n",
       "      <td>0.184773</td>\n",
       "      <td>0.244234</td>\n",
       "      <td>0.104279</td>\n",
       "      <td>0.136835</td>\n",
       "      <td>0.330112</td>\n",
       "      <td>0.238128</td>\n",
       "      <td>0.300729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268209</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151871</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.241353</td>\n",
       "      <td>0.492494</td>\n",
       "      <td>0.292385</td>\n",
       "      <td>0.019761</td>\n",
       "      <td>0.030654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.398088</td>\n",
       "      <td>0.181160</td>\n",
       "      <td>0.190212</td>\n",
       "      <td>0.236984</td>\n",
       "      <td>0.044125</td>\n",
       "      <td>0.157946</td>\n",
       "      <td>0.424532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052688</td>\n",
       "      <td>0.468951</td>\n",
       "      <td>0.151871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105986</td>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.156893</td>\n",
       "      <td>0.078106</td>\n",
       "      <td>0.049101</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082211</td>\n",
       "      <td>0.062361</td>\n",
       "      <td>0.211939</td>\n",
       "      <td>0.095926</td>\n",
       "      <td>0.086769</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.123118</td>\n",
       "      <td>0.122725</td>\n",
       "      <td>0.310733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319964</td>\n",
       "      <td>0.187701</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.105986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286814</td>\n",
       "      <td>0.125763</td>\n",
       "      <td>0.374823</td>\n",
       "      <td>0.168674</td>\n",
       "      <td>0.219726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>0.250971</td>\n",
       "      <td>0.151870</td>\n",
       "      <td>0.355595</td>\n",
       "      <td>0.306186</td>\n",
       "      <td>0.352248</td>\n",
       "      <td>0.306206</td>\n",
       "      <td>0.264092</td>\n",
       "      <td>0.253476</td>\n",
       "      <td>0.162528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">scale4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">vanishing_point</th>\n",
       "      <th>245</th>\n",
       "      <td>0.224843</td>\n",
       "      <td>0.246369</td>\n",
       "      <td>0.338090</td>\n",
       "      <td>0.294132</td>\n",
       "      <td>0.254244</td>\n",
       "      <td>0.304206</td>\n",
       "      <td>0.335670</td>\n",
       "      <td>0.348492</td>\n",
       "      <td>0.196506</td>\n",
       "      <td>0.236015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273163</td>\n",
       "      <td>0.145133</td>\n",
       "      <td>0.277158</td>\n",
       "      <td>0.290480</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215253</td>\n",
       "      <td>0.104051</td>\n",
       "      <td>0.375142</td>\n",
       "      <td>0.153802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.555061</td>\n",
       "      <td>0.380135</td>\n",
       "      <td>0.495111</td>\n",
       "      <td>0.533161</td>\n",
       "      <td>0.543601</td>\n",
       "      <td>0.464897</td>\n",
       "      <td>0.531352</td>\n",
       "      <td>0.332438</td>\n",
       "      <td>0.455332</td>\n",
       "      <td>0.461132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428144</td>\n",
       "      <td>0.196375</td>\n",
       "      <td>0.329311</td>\n",
       "      <td>0.339270</td>\n",
       "      <td>0.391882</td>\n",
       "      <td>0.215253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366192</td>\n",
       "      <td>0.376202</td>\n",
       "      <td>0.551576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.428160</td>\n",
       "      <td>0.259019</td>\n",
       "      <td>0.286163</td>\n",
       "      <td>0.458115</td>\n",
       "      <td>0.398085</td>\n",
       "      <td>0.287108</td>\n",
       "      <td>0.404336</td>\n",
       "      <td>0.491371</td>\n",
       "      <td>0.364493</td>\n",
       "      <td>0.249846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500920</td>\n",
       "      <td>0.132337</td>\n",
       "      <td>0.480770</td>\n",
       "      <td>0.217922</td>\n",
       "      <td>0.357634</td>\n",
       "      <td>0.104051</td>\n",
       "      <td>0.366192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474106</td>\n",
       "      <td>0.458446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.346852</td>\n",
       "      <td>0.265879</td>\n",
       "      <td>0.371492</td>\n",
       "      <td>0.433612</td>\n",
       "      <td>0.491487</td>\n",
       "      <td>0.402992</td>\n",
       "      <td>0.457202</td>\n",
       "      <td>0.438148</td>\n",
       "      <td>0.237683</td>\n",
       "      <td>0.304326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581422</td>\n",
       "      <td>0.132081</td>\n",
       "      <td>0.352693</td>\n",
       "      <td>0.303551</td>\n",
       "      <td>0.435573</td>\n",
       "      <td>0.375142</td>\n",
       "      <td>0.376202</td>\n",
       "      <td>0.474106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.643557</td>\n",
       "      <td>0.458602</td>\n",
       "      <td>0.512385</td>\n",
       "      <td>0.522883</td>\n",
       "      <td>0.496421</td>\n",
       "      <td>0.488303</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>0.366798</td>\n",
       "      <td>0.493343</td>\n",
       "      <td>0.419848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476658</td>\n",
       "      <td>0.372813</td>\n",
       "      <td>0.233809</td>\n",
       "      <td>0.350863</td>\n",
       "      <td>0.414878</td>\n",
       "      <td>0.153802</td>\n",
       "      <td>0.551576</td>\n",
       "      <td>0.458446</td>\n",
       "      <td>0.315646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28750 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "img                                                 0         1         2  \\\n",
       "study            scale  model           img                                 \n",
       "complexity order scale8 autoencoding    0    0.000000  0.065853  0.268209   \n",
       "                                        1    0.065853  0.000000  0.196143   \n",
       "                                        2    0.268209  0.196143  0.000000   \n",
       "                                        3    0.052688  0.468951  0.151871   \n",
       "                                        4    0.319964  0.187701  0.152050   \n",
       "...                                               ...       ...       ...   \n",
       "                 scale4 vanishing_point 245  0.224843  0.246369  0.338090   \n",
       "                                        246  0.555061  0.380135  0.495111   \n",
       "                                        247  0.428160  0.259019  0.286163   \n",
       "                                        248  0.346852  0.265879  0.371492   \n",
       "                                        249  0.643557  0.458602  0.512385   \n",
       "\n",
       "img                                                 3         4         5  \\\n",
       "study            scale  model           img                                 \n",
       "complexity order scale8 autoencoding    0    0.052688  0.319964  0.298544   \n",
       "                                        1    0.468951  0.187701  0.216722   \n",
       "                                        2    0.151871  0.152050  0.241353   \n",
       "                                        3    0.000000  0.105986  0.093960   \n",
       "                                        4    0.105986  0.000000  0.286814   \n",
       "...                                               ...       ...       ...   \n",
       "                 scale4 vanishing_point 245  0.294132  0.254244  0.304206   \n",
       "                                        246  0.533161  0.543601  0.464897   \n",
       "                                        247  0.458115  0.398085  0.287108   \n",
       "                                        248  0.433612  0.491487  0.402992   \n",
       "                                        249  0.522883  0.496421  0.488303   \n",
       "\n",
       "img                                                 6         7         8  \\\n",
       "study            scale  model           img                                 \n",
       "complexity order scale8 autoencoding    0    0.303844  0.338253  0.080624   \n",
       "                                        1    0.145107  0.207201  0.228692   \n",
       "                                        2    0.492494  0.292385  0.019761   \n",
       "                                        3    0.156893  0.078106  0.049101   \n",
       "                                        4    0.125763  0.374823  0.168674   \n",
       "...                                               ...       ...       ...   \n",
       "                 scale4 vanishing_point 245  0.335670  0.348492  0.196506   \n",
       "                                        246  0.531352  0.332438  0.455332   \n",
       "                                        247  0.404336  0.491371  0.364493   \n",
       "                                        248  0.457202  0.438148  0.237683   \n",
       "                                        249  0.459728  0.366798  0.493343   \n",
       "\n",
       "img                                                 9  ...       240  \\\n",
       "study            scale  model           img            ...             \n",
       "complexity order scale8 autoencoding    0    0.168532  ...  0.162140   \n",
       "                                        1   -0.083858  ... -0.056059   \n",
       "                                        2    0.030654  ...  0.027897   \n",
       "                                        3   -0.082435  ... -0.082211   \n",
       "                                        4    0.219726  ...  0.261819   \n",
       "...                                               ...  ...       ...   \n",
       "                 scale4 vanishing_point 245  0.236015  ...  0.273163   \n",
       "                                        246  0.461132  ...  0.428144   \n",
       "                                        247  0.249846  ...  0.500920   \n",
       "                                        248  0.304326  ...  0.581422   \n",
       "                                        249  0.419848  ...  0.476658   \n",
       "\n",
       "img                                               241       242       243  \\\n",
       "study            scale  model           img                                 \n",
       "complexity order scale8 autoencoding    0    0.097780  0.153127  0.393909   \n",
       "                                        1    0.169147  0.402768  0.184773   \n",
       "                                        2    0.333322  0.130600  0.398088   \n",
       "                                        3    0.062361  0.211939  0.095926   \n",
       "                                        4    0.250971  0.151870  0.355595   \n",
       "...                                               ...       ...       ...   \n",
       "                 scale4 vanishing_point 245  0.145133  0.277158  0.290480   \n",
       "                                        246  0.196375  0.329311  0.339270   \n",
       "                                        247  0.132337  0.480770  0.217922   \n",
       "                                        248  0.132081  0.352693  0.303551   \n",
       "                                        249  0.372813  0.233809  0.350863   \n",
       "\n",
       "img                                               244       245       246  \\\n",
       "study            scale  model           img                                 \n",
       "complexity order scale8 autoencoding    0    0.127255  0.232155  0.314069   \n",
       "                                        1    0.244234  0.104279  0.136835   \n",
       "                                        2    0.181160  0.190212  0.236984   \n",
       "                                        3    0.086769  0.001098  0.096970   \n",
       "                                        4    0.306186  0.352248  0.306206   \n",
       "...                                               ...       ...       ...   \n",
       "                 scale4 vanishing_point 245  0.362110  0.000000  0.215253   \n",
       "                                        246  0.391882  0.215253  0.000000   \n",
       "                                        247  0.357634  0.104051  0.366192   \n",
       "                                        248  0.435573  0.375142  0.376202   \n",
       "                                        249  0.414878  0.153802  0.551576   \n",
       "\n",
       "img                                               247       248       249  \n",
       "study            scale  model           img                                \n",
       "complexity order scale8 autoencoding    0    0.187343  0.051893  0.086527  \n",
       "                                        1    0.330112  0.238128  0.300729  \n",
       "                                        2    0.044125  0.157946  0.424532  \n",
       "                                        3    0.123118  0.122725  0.310733  \n",
       "                                        4    0.264092  0.253476  0.162528  \n",
       "...                                               ...       ...       ...  \n",
       "                 scale4 vanishing_point 245  0.104051  0.375142  0.153802  \n",
       "                                        246  0.366192  0.376202  0.551576  \n",
       "                                        247  0.000000  0.474106  0.458446  \n",
       "                                        248  0.474106  0.000000  0.315646  \n",
       "                                        249  0.458446  0.315646  0.000000  \n",
       "\n",
       "[28750 rows x 250 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspi_rdms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x77a98d736ca0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_studyscale = dfspi_rdms.groupby([\"study\", \"scale\"])\n",
    "l = []\n",
    "for gk in g_studyscale.groups.keys():\n",
    "    gss = g_studyscale.get_group(gk).groupby(\"model\")\n",
    "\n",
    "    rdm = pd.DataFrame(0, index=_models, columns=_models)\n",
    "    for mo1, mo2 in combinations(gss.groups.keys(), 2):\n",
    "        c = correlate_rdms(gss.get_group(mo1), gss.get_group(mo2))[0]\n",
    "        rdm.loc[mo1, mo2], rdm.loc[mo2, mo1] = c, c\n",
    "    rdm = rdm.assign(study=gk[0], scale=gk[1]).set_index([\"study\",\"scale\"], append=True).reorder_levels([\"study\",\"scale\",None])\n",
    "    l.append(rdm)\n",
    "\n",
    "predictor_rdm_3 = pd.concat(l)\n",
    "sns.heatmap(predictor_rdm_3.loc[(\"short presentation\",\"scale4\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_rdm_3.to_hdf(\n",
    "    os.path.join(PATH_RESULTS, \"spatial integration\", \"predictor3 bestpredlayer.hd5\"),\n",
    "    key=\"predictor_rdm_3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_rdm_3 = pd.DataFrame(0, index=_models, columns=_models)\n",
    "# g = dfspi_rdms.groupby(\"model\")\n",
    "\n",
    "# for gk1, gk2 in combinations(g.groups.keys(), 2):\n",
    "#     c = correlate_rdms(g.get_group(gk1), g.get_group(gk2))[0]\n",
    "#     predictor_rdm_3.loc[gk1, gk2], predictor_rdm_3.loc[gk2, gk1] = c, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integration is localized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize node score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize within layer heatmaps\n",
    "\n",
    "# exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial correlation per image per net, correlate these netXnet\n",
    "# test if integration scores are still correlating to beauty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old version: searchlight scoring best predicting nets\n",
    "\n",
    "Representative net from each category:\n",
    "\n",
    "semantic:   segment semantic \\\n",
    "2D:         segment unsup 2d \\\n",
    "3D:         depth euclidean\n",
    "\n",
    "> from each class of networks take the one layer with highest integration beauty score across networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load integration-beauty correlation for 3 nets\n",
    "SCALE_NAME = \"scale4\"\n",
    "MODEL_SEMANTIC = \"segment_semantic\"\n",
    "MODEL_2D = \"segment_unsup2d\"\n",
    "MODEL_3D = \"depth_euclidean\"\n",
    "\n",
    "\n",
    "def load_ibcorr(m):\n",
    "    l = []\n",
    "    for s in STUDY_NAMES:\n",
    "        d = pd.read_csv(os.path.join(PATH_IB_CORRELATIONS, m, s, SCALE_NAME, 'ib_correlations.csv'), header=None)\n",
    "        d.insert(0, 'study', s)\n",
    "        d = d.reset_index().rename(columns={\"index\":\"layer\", 0:\"ibcorr\"})\n",
    "        l.append(d)\n",
    "    \n",
    "    return pd.concat(l).reset_index(drop=True)\n",
    "\n",
    "df_segment_semantic = load_ibcorr(MODEL_SEMANTIC)\n",
    "df_segment_unsup2d = load_ibcorr(MODEL_2D)\n",
    "df_depth_euclidean = load_ibcorr(MODEL_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find layers with highest integration-beauty correlation\n",
    "# get scale and layer num of layer with highest correlation\n",
    "best_semantic = df_segment_semantic.iloc[df_segment_semantic.ibcorr.idxmax(),:]\n",
    "best_2d = df_segment_unsup2d.iloc[df_segment_unsup2d.ibcorr.idxmax(),:]\n",
    "best_3d = df_depth_euclidean.iloc[df_depth_euclidean.ibcorr.idxmax(),:]\n",
    "print(best_semantic)\n",
    "print(best_2d)\n",
    "print(best_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup nets for extracting activations from best layer\n",
    "def setup_singlelayer(model_name: str, layer_idx: int):\n",
    "    \"\"\" Setup activation extractor for a single layer of a tasnomomy network\n",
    "    \"\"\"\n",
    "    VisualPriorRepresentation._load_unloaded_nets([model_name])\n",
    "    net = VisualPriorRepresentation.feature_task_to_net[model_name]\n",
    "\n",
    "    _, eval_nodes = get_graph_node_names(net)\n",
    "    return_nodes = {node:node for node in eval_nodes if \"conv\" in node or 'fc' in node}\n",
    "    \n",
    "    layer_name = list(return_nodes.keys())[layer_idx]\n",
    "    return create_feature_extractor(net, return_nodes={layer_name:layer_name}), layer_name\n",
    "\n",
    "activation_extractor_semantic, layername_best_semantic = setup_singlelayer(MODEL_SEMANTIC, best_semantic.layer)\n",
    "activation_extractor_2d, layername_best_2d = setup_singlelayer(MODEL_2D, best_2d.layer)\n",
    "activation_extractor_3d, layername_best_3d = setup_singlelayer(MODEL_3D, best_3d.layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do integration beauty scoring with node pools sweeping along 3D axis\n",
    "- full width 2D layer pools along all three axis\n",
    "- 3D cubic pool along all three axis (vary in size)\n",
    "\n",
    "Effectively just need to change the PatternGenerator, and switch from iterating subset num to iterating the pattern generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_SEMANTIC_PLACES1 = './searchlight/singlelayer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### semantic net\n",
    "\n",
    "semantic, places1, best layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load images & activation shape (semantic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(os.path.join(PATH_IMAGES, \"places1\", best_semantic.scale))\n",
    "\n",
    "num_images = dataset.img_count\n",
    "\n",
    "# activation shape as Dict\n",
    "dummy_image = next(iter(dataset))\n",
    "net_activation = activation_extractor_semantic(dummy_image[0])\n",
    "net_activation = OrderedDict(net_activation)\n",
    "activation_shapes = taskonomy_activation_layer_shapes(net_activation)\n",
    "\n",
    "# activation shape as Tensor\n",
    "activation_shape_semantic = list(activation_shapes.values())[0][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single image(s)\n",
    "\n",
    "can only map back integration-beauty score for whole dataset, however, its possible, that in every image something different gets integrated, therefore it wouldn't make sense to map back a score for the whole dataset to individual nodes.\n",
    "\n",
    "Since we know that (at least some) integration, and subsets integration, is meaningfull, we map back integration of individual images onto individual nodes, without correlating this integration with beauty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP VARIABLES ---\n",
    "pat_s = PatternGeneratorSearchlight(\n",
    "    activation_shape_semantic,\n",
    "    layername_best_semantic\n",
    "    )\n",
    "\n",
    "num_layers = 1 # only take activations of best performing layer from each net\n",
    "num_images = 1\n",
    "num_subsets = pat_s.num_subsets\n",
    "\n",
    "# layer x image x subset\n",
    "integration = np.full([num_layers, num_images, num_subsets], np.nan, dtype=np.float64)\n",
    "cnt = 0\n",
    "\n",
    "    \n",
    "# load single image\n",
    "img_id = 0\n",
    "img_full, img_v1, img_v2 = next(iter(dataset))\n",
    "\n",
    "# --- ANALYSIS ---\n",
    "\n",
    "act_full = activation_extractor_semantic(img_full)[layername_best_semantic].squeeze()\n",
    "act_v1 = activation_extractor_semantic(img_v1)[layername_best_semantic].squeeze()\n",
    "act_v2 = activation_extractor_semantic(img_v2)[layername_best_semantic].squeeze()\n",
    "act_avg = (act_v1 + act_v2) / 2.\n",
    "\n",
    "# iterate 3D positions\n",
    "pat_it = iter(pat_s)\n",
    "for subset_num, roi_mask in pat_it:\n",
    "    \n",
    "    subset_act_full = act_full[roi_mask]\n",
    "    subset_act_avg = act_avg[roi_mask]\n",
    "\n",
    "    # calculate integration and store it\n",
    "    subset_integration = -pearsonr(subset_act_full.flatten(), subset_act_avg.flatten())[0]\n",
    "    integration[:,img_id, subset_num] = subset_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration = integration.squeeze(0)\n",
    "integration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_shapes['layer3.4.conv2'] = activation_shape_semantic\n",
    "ns = NetworkScorer(activation_shapes)\n",
    "ns.map_back_scores(integration, pat_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer x image x subset\n",
    "integration = np.full([num_layers,num_images,num_subsets], np.nan, dtype=np.float64)\n",
    "cnt = 0\n",
    "\n",
    "# iterate image set\n",
    "for img_id, (img_full, img_v1, img_v2) in enumerate(iter(dataset)):\n",
    "    if cnt % 30 == 0: print(cnt, end= ' ')\n",
    "    cnt=cnt+1\n",
    "    \n",
    "    # activations as tensors\n",
    "    act_full = activation_extractor_semantic(img_full)[layername_best_semantic].squeeze()\n",
    "    act_v1 = activation_extractor_semantic(img_v1)[layername_best_semantic].squeeze()\n",
    "    act_v2 = activation_extractor_semantic(img_v2)[layername_best_semantic].squeeze()\n",
    "    act_avg = (act_v1 + act_v2) / 2.\n",
    "\n",
    "    # iterate 3D positions in layer\n",
    "    pat_it = iter(pat_s)\n",
    "\n",
    "    for subset_num, roi_mask in pat_it:\n",
    "        \n",
    "        subset_act_full = act_full[roi_mask]\n",
    "        subset_act_avg = act_avg[roi_mask]\n",
    "\n",
    "        # calculate integration and store it\n",
    "        subset_integration = pearsonr(subset_act_full.flatten(), subset_act_avg.flatten())[0]\n",
    "        integration[:,img_id, subset_num] = subset_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_RESULTS, RESULTS_SEMANTIC_PLACES1, \"semantic_integration.npy\"), \"wb\") as f:\n",
    "    np.save(f, integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_RESULTS, RESULTS_SEMANTIC_PLACES1, \"semantic_integration.npy\"), 'rb') as f:\n",
    "    integration = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beauty ratings\n",
    "beauty_ratings = ImageDataset(\n",
    "    os.path.join(DATA_PATH, DATASET_NAMES[0], SCALE_NAMES[0]),\n",
    "    beauty_ratings_path='behavior/ratings_study1.csv').beauty_ratings\n",
    "\n",
    "# correlate integration with beauty\n",
    "scores = correlate_integration_beauty(integration, beauty_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert integration back to 3D layer space\n",
    "activation_shapes['layer3.4.conv2'] = activation_shape_semantic\n",
    "ns = NetworkScorer(activation_shapes)\n",
    "ns.map_back_scores(scores, pat_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize spatial integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot all heatmaps with the same absoloute color scale\n",
    "with PdfPages('integration heatmap semantic img0.pdf') as pdf:\n",
    "    for vertical_slice in ns.scores[layername_best_semantic].squeeze():\n",
    "        sns.heatmap(vertical_slice)\n",
    "        pdf.savefig()\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ns.scores[layername_best_semantic]\n",
    "t.min(), t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.flatten()\n",
    "num_bins = 30\n",
    "hist = torch.histc(t, bins=num_bins, min=torch.min(t).item(), max=torch.max(t).item())\n",
    "\n",
    "# Define the edges of the bins\n",
    "bin_edges = torch.linspace(torch.min(t).item(), torch.max(t).item(), steps=num_bins + 1)\n",
    "\n",
    "# Plot the histogram using Matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(t.numpy(), bins=bin_edges.numpy(), edgecolor='black')\n",
    "plt.title('Histogram of Tensor Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inte = ns.scores[layername_best_semantic].squeeze()\n",
    "\n",
    "# plot only highest integrating nodes\n",
    "with PdfPages('integration heatmap semantic img0 best.pdf') as pdf:\n",
    "    for vertical_slice in inte:\n",
    "        sns.heatmap(vertical_slice)\n",
    "        pdf.savefig()\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation testing\n",
    "\n",
    "Repeat analysis for randomly shuffeled integration values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "integration = integration.squeeze(0)\n",
    "integration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_pt = torch.tensor(integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_pt.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_randomized = integration_pt[torch.randperm(integration_pt.nelement())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_randomized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = NetworkScorer(activation_shapes)\n",
    "ns.map_back_scores(integration_randomized.unsqueeze(0), pat_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random pattern heatmaps for visual comparison\n",
    "# TODO generate permutation distribution\n",
    "with PdfPages('integration heatmap random scores.pdf') as pdf:\n",
    "    for vertical_slice in ns.scores[layername_best_semantic]:\n",
    "        sns.heatmap(vertical_slice)\n",
    "        pdf.savefig()\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_shapes[\"layer2.3.conv1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are integration beauty scores meaningfull ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do the top nodes integration predict beauty better than the bottom nodes (or any other random 10%) ? \\\n",
    "- Use spatially coherent subsets to calculate scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random pattern scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_singlelayer_analysis(dataset, activation_extractor, num_subsets, frac):\n",
    "    num_layers = 1 # only take activations of best performing layer from each net\n",
    "    num_images = dataset.img_count\n",
    "\n",
    "    # get shapes of activation\n",
    "    dummy_image = next(iter(dataset))\n",
    "    net_activation = activation_extractor(dummy_image[0])\n",
    "    net_activation = OrderedDict(net_activation)\n",
    "    activation_shapes = taskonomy_activation_layer_shapes(net_activation)\n",
    "    \n",
    "    pat = Pattern_Generator(\n",
    "        num_subsets,\n",
    "        activation_shapes,\n",
    "        frac=frac\n",
    "        )\n",
    "\n",
    "    # layer x image x subset\n",
    "    integration = np.full([num_layers,num_images,num_subsets], np.nan, dtype=np.float64)\n",
    "    cnt = 0\n",
    "\n",
    "    # iterate image set\n",
    "    for img_id, (img_full, img_v1, img_v2) in enumerate(iter(dataset)):\n",
    "        if cnt % 30 == 0: print(cnt, end= ' ')\n",
    "        cnt=cnt+1\n",
    "        \n",
    "        act_full = Activation_Pattern(activation_extractor(img_full))\n",
    "        act_v1 = Activation_Pattern(activation_extractor(img_v1))\n",
    "        act_v2 = Activation_Pattern(activation_extractor(img_v2))\n",
    "        act_avg = Activation_Pattern.average(act_v1, act_v2)\n",
    "\n",
    "        # iterate node subsets\n",
    "        for subset_num in range(num_subsets):\n",
    "            subset_mask = pat.get_subset_pattern(subset_num)\n",
    "            \n",
    "            subset_act_full = act_full[subset_mask]\n",
    "            subset_act_avg = act_avg[subset_mask]\n",
    "\n",
    "            # calculate integration and store it\n",
    "            subset_integration = Activation_Pattern.calculate_integration_coeff(subset_act_full, subset_act_avg)\n",
    "            integration[:,img_id, subset_num] = subset_integration\n",
    "    \n",
    "    ns = NetworkScorer(activation_shapes)\n",
    "    ns.map_back_scores(integration, pat)\n",
    "\n",
    "    return integration, ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subsets = 10000\n",
    "# run analysis for semantic\n",
    "dataset = ImageDataset(os.path.join(DATA_PATH, \"places1\", best_semantic.scale))\n",
    "\n",
    "integration_semantic_frac01, ns_semantic_frac01 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_semantic,\n",
    "    num_subsets,\n",
    "    frac=0.01\n",
    "    )\n",
    "\n",
    "integration_semantic_frac10, ns_semantic_frac10 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_semantic,\n",
    "    num_subsets,\n",
    "    frac=0.10\n",
    "    )\n",
    "\n",
    "integration_semantic_frac90, ns_semantic_frac90= run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_semantic,\n",
    "    num_subsets,\n",
    "    frac=0.90\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_semantic_frac01.shape, ns_semantic_frac01.scores['layer3.4.conv2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(integration_semantic_frac01), type(ns_semantic_frac01.scores['layer3.4.conv2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subsets = 10000\n",
    "\n",
    "# run analysis for semantic\n",
    "dataset = ImageDataset(os.path.join(DATA_PATH, \"places1\", best_semantic.scale))\n",
    "\n",
    "integration_semantic_frac01, ns_semantic_frac01 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_semantic,\n",
    "    num_subsets,\n",
    "    frac=0.01\n",
    "    )\n",
    "\n",
    "integration_semantic_frac10, ns_semantic_frac10 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_semantic,\n",
    "    num_subsets,\n",
    "    frac=0.10\n",
    "    )\n",
    "\n",
    "integration_semantic_frac90, ns_semantic_frac90= run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_semantic,\n",
    "    num_subsets,\n",
    "    frac=0.90\n",
    "    )\n",
    "\n",
    "# run analysis for 2d\n",
    "dataset = ImageDataset(os.path.join(DATA_PATH, \"places1\", best_2d.scale))\n",
    "\n",
    "integration_2d_frac01, ns_2d_frac01 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_2d,\n",
    "    num_subsets,\n",
    "    frac=0.01\n",
    "    )\n",
    "\n",
    "integration_2d_frac10, ns_2d_frac10 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_2d,\n",
    "    num_subsets,\n",
    "    frac=0.10\n",
    "    )\n",
    "\n",
    "integration_2d_frac90, ns_2d_frac90= run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_2d,\n",
    "    num_subsets,\n",
    "    frac=0.90\n",
    "    )\n",
    "\n",
    "# run analysis for 3d\n",
    "dataset = ImageDataset(os.path.join(DATA_PATH, \"places1\", best_3d.scale))\n",
    "\n",
    "integration_3d_frac01, ns_3d_frac01 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_3d,\n",
    "    num_subsets,\n",
    "    frac=0.01\n",
    "    )\n",
    "\n",
    "integration_3d_frac10, ns_3d_frac10 = run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_3d,\n",
    "    num_subsets,\n",
    "    frac=0.10\n",
    "    )\n",
    "\n",
    "integration_3d_frac90, ns_3d_frac90= run_singlelayer_analysis(\n",
    "    dataset,\n",
    "    activation_extractor_3d,\n",
    "    num_subsets,\n",
    "    frac=0.90\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_SINGLELAYER_ANALYSIS = './analysis results singlelayer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "files_i = [\"integration\"+netclass+fracsize+\".npy\"\n",
    "           for netclass, fracsize\n",
    "           in product([\"_semantic\",\"_2d\",\"_3d\"], [\"_frac01\",\"_frac10\",\"_frac90\"])]\n",
    "files_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_n = [\"integration\"+netclass+fracsize+\".pkl\"\n",
    "           for netclass, fracsize\n",
    "           in product([\"_semantic\",\"_2d\",\"_3d\"], [\"_frac01\",\"_frac10\",\"_frac90\"])]\n",
    "files_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_integration = [integration_semantic_frac01, integration_semantic_frac10, integration_semantic_frac90,\n",
    "                      integration_2d_frac01, integration_2d_frac10, integration_2d_frac90,\n",
    "                      integration_3d_frac01, integration_3d_frac10, integration_3d_frac90]\n",
    "\n",
    "objects_nodescoring = [ns_semantic_frac01, ns_semantic_frac10, ns_semantic_frac90,\n",
    "                       ns_2d_frac01, ns_2d_frac10, ns_2d_frac90,\n",
    "                       ns_3d_frac01, ns_3d_frac10, ns_3d_frac90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_i, file_n, array_i, array_n in zip(files_i, files_n, arrays_integration, objects_nodescoring):\n",
    "    with open(os.path.join(FOLDER_SINGLELAYER_ANALYSIS, file_i), \"wb\") as f1:\n",
    "        np.save(f1, array_i)\n",
    "    \n",
    "    with open(os.path.join(FOLDER_SINGLELAYER_ANALYSIS, file_n), \"wb\") as f2:\n",
    "        pickle.dump(array_n, f2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manipulating integratability and watch response of network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "gradually perform image transformations shown to break integration to:\n",
    "- test where in the network integration takes place\n",
    "- test whether different manipulations break different clusters first\n",
    "\n",
    "\n",
    "\n",
    "Do integration beauty scoring with node pools sweeping along 3D axis\n",
    "- full width 2D layer pools along all three axis\n",
    "- 3D cubic pool along all three axis (vary in size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permutation test for integration: generate permutation distribution by calculating integration at each location in the layer to random input. input real image, calculate clusters of significant integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do semantic / 2d / 3d nets integrate different features (semantic vs structural) or are they essentially integrating the same features but in a different way ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do different manipulations break integration in different ways ?\n",
    "Look at:\n",
    "    a) How much manipulation does is need to break integration ?\n",
    "    b) In which networks / layers / scales / datasets is integration broken in which order ?\n",
    "    c) Which image's integration is broken first ?\n",
    "\n",
    "\n",
    "Collect different ways of manipulating images to break integration.\n",
    "    - Do these\n",
    "    a) all break integration the same way\n",
    "    b) cluster into groups in the way in which they break integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pixelated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(os.path.join(DATA_PATH, \"places1\", best_semantic.scale))\n",
    "it_dataset = iter(dataset)\n",
    "\n",
    "im = next(it_dataset)[0].squeeze()\n",
    "im2 = next(it_dataset)[2].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.min(), im.max(), im2.min(), im2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im + im.min().abs()\n",
    "im = im / im.max()\n",
    "#d2 = 1-d2\n",
    "im.min(), im.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a fraction of the pixels on the 256x256 grid and permute them\n",
    "pix_degree = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pix = torch.rand((256,256)) < pix_degree\n",
    "mask_original = ~mask_pix\n",
    "\n",
    "# number of pixels that are pixeled, this is not exactly the pix degree due to randomness\n",
    "n_pix = im[:,mask_pix].shape[1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_im = torch.full_like(im, np.nan)\n",
    "\n",
    "# non-pixeled part\n",
    "pix_im[:,mask_original] = im[:,mask_original]\n",
    "\n",
    "# pixeled part\n",
    "pix_im[:,mask_pix] = im[:,mask_pix][:,torch.randperm(n_pix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelate_image(im, pix_degree: float):\n",
    "    \"\"\" Pixelate a 256x256 image\"\"\"\n",
    "    mask_pix = torch.rand((256,256)) < pix_degree\n",
    "    mask_original = ~mask_pix\n",
    "\n",
    "    # number of pixels that are pixeled, this is not exactly the pix degree due to randomness\n",
    "    n_pix = im[:,mask_pix].shape[1] \n",
    "\n",
    "    pix_im = torch.full_like(im, np.nan)\n",
    "\n",
    "    # non-pixeled part\n",
    "    pix_im[:,mask_original] = im[:,mask_original]\n",
    "\n",
    "    # pixeled part\n",
    "    pix_im[:,mask_pix] = im[:,mask_pix][:,torch.randperm(n_pix)]\n",
    "\n",
    "    return pix_im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_print(im):\n",
    "    im = im + im.min().abs()\n",
    "    im = im / im.max()\n",
    "    plt.imshow(im.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_print(pixelate_image(im, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: since at 0.25 theres already a strong (subjective) visual disturbance,\n",
    "# maybe apply a logarithmic scale with image pixelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: as annother gradual transformation, implement a gradual low-pass filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imageversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(127/127.5-1, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1,0],[0,1]]).repeat_interleave(2,dim=0).repeat_interleave(2,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkerboard(scale, size=256):\n",
    "    msc = torch.tensor([[1, 0] * (scale//2), [0, 1] * (scale//2)] * (scale//2))\n",
    "    return msc.repeat_interleave(size//scale, dim=0).repeat_interleave(size//scale, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_checkerboard(64).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get activations for pixelated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_extractor_semantic().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_extractor_semantic(torch.rand_like(dummy_image[0]))['layer3.4.conv2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  get distribution of integration / ib-correlation of random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image\n",
    "ac = activation_extractor_semantic(torch.rand_like(dummy_image[0]))['layer3.4.conv2']\n",
    "ac = ac.squeeze()\n",
    "ac.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get previous one at each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1, l2 in zip(ac_full, ac_avg):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visual inspection\n",
    "are there maybe any clusters of integration to random images, already revealing a integration structure in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get activation of actual image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test where there are significant clusters of integration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
