{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map to 3D space: cumulative correlation\n",
    "from each voxel inside 3x3x3 box aroung location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = subset_correlations.loc[mo].correlation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = subset_correlations.loc[mo].correlation.values[:, np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[~subset_significance.loc[mo].values] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_correlations.loc[mo].pvalue.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.map_back_scores(scores, pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3d = list(ns.scores.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# localized ibcorr outperforms whole layer ibcorr\n",
    "still need to include comapre correlations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat = beauty_ratings[\"study3_places2.csv\"].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfibc = load_ibcorr(PATH_IBCORR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "autoencoding        0.362207\n",
       "class_scene         0.480581\n",
       "curvature           0.455136\n",
       "egomotion           0.371716\n",
       "keypoints3d         0.460132\n",
       "nonfixated_pose     0.401111\n",
       "normal              0.503802\n",
       "reshading           0.458294\n",
       "room_layout         0.483429\n",
       "segment_unsup25d    0.469479\n",
       "segment_unsup2d     0.374942\n",
       "vanishing_point     0.416983\n",
       "Name: correlation, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset_correlations.correlation.groupby(\"model\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ibcorr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>layer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>autoencoding</th>\n",
       "      <th>25</th>\n",
       "      <td>0.252745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_scene</th>\n",
       "      <th>36</th>\n",
       "      <td>0.386861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curvature</th>\n",
       "      <th>32</th>\n",
       "      <td>0.480282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>egomotion</th>\n",
       "      <th>33</th>\n",
       "      <td>0.280207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keypoints3d</th>\n",
       "      <th>41</th>\n",
       "      <td>0.441996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonfixated_pose</th>\n",
       "      <th>41</th>\n",
       "      <td>0.280803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <th>41</th>\n",
       "      <td>0.419579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reshading</th>\n",
       "      <th>46</th>\n",
       "      <td>0.454562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_layout</th>\n",
       "      <th>41</th>\n",
       "      <td>0.424132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_unsup25d</th>\n",
       "      <th>35</th>\n",
       "      <td>0.429413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_unsup2d</th>\n",
       "      <th>35</th>\n",
       "      <td>0.403273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanishing_point</th>\n",
       "      <th>18</th>\n",
       "      <td>0.384978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ibcorr\n",
       "model            layer          \n",
       "autoencoding     25     0.252745\n",
       "class_scene      36     0.386861\n",
       "curvature        32     0.480282\n",
       "egomotion        33     0.280207\n",
       "keypoints3d      41     0.441996\n",
       "nonfixated_pose  41     0.280803\n",
       "normal           41     0.419579\n",
       "reshading        46     0.454562\n",
       "room_layout      41     0.424132\n",
       "segment_unsup25d 35     0.429413\n",
       "segment_unsup2d  35     0.403273\n",
       "vanishing_point  18     0.384978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfibc.loc[(_models_ordered, \"complexity order\", \"scale4\", slice(None))].droplevel(\n",
    "    [\"study\", \"scale\"]\n",
    ").loc[bestlayers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestlayers = (\n",
    "    dfibc.loc[(_models_ordered, \"complexity order\", \"scale4\", slice(None))]\n",
    "    .droplevel([\"study\", \"scale\"])\n",
    "    .groupby(\"model\")\n",
    "    .idxmax()\n",
    "    .ibcorr.map(lambda x: x[1])\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .values.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster permutation distributions\n",
    "cluster based permutation testing of pvalue clusters, at each scale  & study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation test size for all tets\n",
    "n_permutations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calculateclusters(scale, model, layer, study, n_permutations):\n",
    "    \"\"\"\n",
    "    Wrapper around permutation_distribution() that handles\n",
    "    loading input and saving output for the given data.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(\n",
    "        os.path.join(\n",
    "            PATH_PERMDISTR,\n",
    "            scale,\n",
    "            \"permdistr \" + study + \" \" + model + \" \" + str(layer) + \".npy\",\n",
    "        ),\n",
    "        \"wb\",\n",
    "    ) as file:\n",
    "        np.save(\n",
    "            file,\n",
    "            permutation_distribtion(\n",
    "                pd.read_hdf(\n",
    "                    os.path.join(\n",
    "                        PATH_SSINT,\n",
    "                        scale,\n",
    "                        study2dataset(study) + \" \" + model + \" \" + str(layer) + \".h5\",\n",
    "                    ),\n",
    "                    key=\"subset integration\",\n",
    "                ),\n",
    "                studyratings(study),\n",
    "                layer,\n",
    "                n_permutations,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"scale2\"\n",
    "model = \"reshading\"\n",
    "layer = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study1\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to key being with and underscore in this one!!!\n",
    "study = \"study3\"\n",
    "with open(\n",
    "    os.path.join(\n",
    "        PATH_PERMDISTR,\n",
    "        scale,\n",
    "        \"permdistr \" + study + \" \" + model + \" \" + str(layer) + \".npy\",\n",
    "    ),\n",
    "    \"wb\",\n",
    ") as file:\n",
    "    np.save(\n",
    "        file,\n",
    "        permutation_distribtion(\n",
    "            pd.read_hdf(\n",
    "                os.path.join(\n",
    "                    PATH_SSINT,\n",
    "                    scale,\n",
    "                    study2dataset(study) + \" \" + model + \" \" + str(layer) + \".h5\",\n",
    "                ),\n",
    "                key=\"subset_integration\",\n",
    "            ),\n",
    "            studyratings(study),\n",
    "            layer,\n",
    "            n_permutations,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study3\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_calculateclusters(scale, model, layer, \"study4\", n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"scale4\"\n",
    "model = \"segment_unsup2d\"\n",
    "layer = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study1\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study2\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study3\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study4\", n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"scale8\"\n",
    "model = \"vanishing_point\"\n",
    "layer = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study1\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study2\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study3\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_calculateclusters(scale, model, layer, \"study4\", n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"scale16\"\n",
    "model = \"segment_unsup25d\"\n",
    "layer = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study1\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study2\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study3\", n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calculateclusters(scale, model, layer, \"study4\", n_permutations)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
