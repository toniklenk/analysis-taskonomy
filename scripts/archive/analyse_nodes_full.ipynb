{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis script: analyse_nodes\n",
    "calculates correlation of integration and beauty for subsets of DNN nodes and maps this score back onto the nodes of these indivifidual subsets.\n",
    "\n",
    "do this for hundrets/thousands of subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# modified visualpriors library\n",
    "from transforms import VisualPriorRepresentation\n",
    "\n",
    "from classes_analyse_nodes import (\n",
    "    ImageDataset,\n",
    "    Pattern_Generator,\n",
    "    Activation_Pattern,\n",
    "    NetworkScorer,\n",
    "    calculate_integration_coeff,\n",
    "    taskonomy_activation_layer_shapes,\n",
    "    correlate_integration_beauty,\n",
    "    )\n",
    "\n",
    "import torch\n",
    "import torch.utils.model_zoo # required to load nets\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = ('places1', 'places2', 'oasis')\n",
    "SCALE_NAMES = ('scale2','scale4','scale8','scale16','scale32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data_256x256'\n",
    "BEHAVIOR_PATH = './behavior'\n",
    "RESULTS_PATH = './results_taskonomy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VisualPrior.viable_feature_tasks\n",
    "MODEL_NAMES = ('autoencoding','depth_euclidean','jigsaw','reshading',\n",
    "               'edge_occlusion','keypoints2d','room_layout', #'colorization' currently not working\n",
    "               'curvature','edge_texture','keypoints3d','segment_unsup2d',\n",
    "               'class_object','egomotion','nonfixated_pose','segment_unsup25d',\n",
    "               'class_scene','fixated_pose','normal','segment_semantic',\n",
    "               'denoising','inpainting','point_matching','vanishing_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_TRANSFORMS = ('untransformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing a NetworkScorer object for saving backprojected scores\n",
    "# TODO needs to be adapted when analysing multiple nets\n",
    "BACKPROJECTED_SCORES_FOLDER = './backprojected_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# include back projection into analysis loop directly so individual subset calculations can be run independently\n",
    "# and i can just let more subset calculations run whenevery i have time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run analysis\n",
    "# map back score into network scorere\n",
    "# save network scorer every 10 subsets\n",
    "# save how many subset iterations were added in a seperate file\n",
    "# optional: write script that allows saving on a button press and then saves latest progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup net\n",
    "model_name = MODEL_NAMES[9] #segment semantic\n",
    "VisualPriorRepresentation._load_unloaded_nets([model_name])\n",
    "net = VisualPriorRepresentation.feature_task_to_net[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup activation extractor\n",
    "_, eval_nodes = get_graph_node_names(net)\n",
    "return_nodes = { node:node for node in eval_nodes if \"conv\" in node or 'fc' in node}\n",
    "activation_extractor = create_feature_extractor(net, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of activation\n",
    "#dummy image\n",
    "dataset = ImageDataset(os.path.join(DATA_PATH, DATASET_NAMES[0], SCALE_NAMES[0]))\n",
    "dummy_image = next(iter(dataset))\n",
    "net_activation = activation_extractor(dummy_image[0])\n",
    "net_activation = OrderedDict(net_activation)\n",
    "# get activation shape\n",
    "activation_shapes = taskonomy_activation_layer_shapes(net_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beauty ratings\n",
    "beauty_ratings = ImageDataset(\n",
    "    os.path.join(DATA_PATH, DATASET_NAMES[0], SCALE_NAMES[0]),\n",
    "    beauty_ratings_path='behavior/ratings_study1.csv').beauty_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = activation_shapes.__len__()\n",
    "num_images = dataset.img_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when running for the first time (for this DNN)\n",
    "ns = NetworkScorer(activation_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integration-beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when running not for the first time (for this DNN)\n",
    "# load existing scores from previously executet iterations\n",
    "iterations = [int(filename[len(\"iteration_\"):])\n",
    "              for filename in os.listdir(BACKPROJECTED_SCORES_FOLDER)]\n",
    "\n",
    "highest_iteration = max(iterations)\n",
    "\n",
    "ns = NetworkScorer.load(os.path.join(BACKPROJECTED_SCORES_FOLDER, \"iteration_\" + str(highest_iteration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    cnt = 0\n",
    "\n",
    "    # new random subsets every time\n",
    "    pat = Pattern_Generator(\n",
    "        subset_batch_size,  \n",
    "        activation_shapes,\n",
    "        frac=0.01\n",
    "        )\n",
    "\n",
    "    # layer x image x subset\n",
    "    integration = np.full([num_layers,num_images,subset_batch_size], np.nan)\n",
    "    integration.shape\n",
    "\n",
    "\n",
    "    # iterate image set\n",
    "    for img_id, (img_full, img_v1, img_v2) in enumerate(iter(dataset)):\n",
    "        if cnt % 100 == 0: print(cnt, end=' ')\n",
    "        cnt=cnt+1\n",
    "        \n",
    "        act_full = Activation_Pattern(activation_extractor(img_full))\n",
    "        act_v1   = Activation_Pattern(activation_extractor(img_v1))\n",
    "        act_v2   = Activation_Pattern(activation_extractor(img_v2))\n",
    "        act_avg  = Activation_Pattern.average(act_v1, act_v2)\n",
    "\n",
    "        # iterate node subsets\n",
    "        for subset_num in range(subset_batch_size):\n",
    "            subset_mask = pat.get_subset_pattern(subset_num)\n",
    "            \n",
    "            subset_act_full = act_full[subset_mask]\n",
    "            subset_act_avg  = act_avg[subset_mask]\n",
    "\n",
    "            # calculate integration and store it\n",
    "            subset_integration = calculate_integration_coeff(subset_act_full, subset_act_avg)\n",
    "            integration[:,img_id, subset_num] = subset_integration\n",
    "    \n",
    "  \n",
    "    # score (correlate) integration-beauty\n",
    "    correlations = correlate_integration_beauty(integration, beauty_ratings)\n",
    "    scores = np.abs(correlations)\n",
    "\n",
    "    # map back scores onto nodes from this iteration of the dataset\n",
    "    ns.map_back_scores(scores, pat)\n",
    "\n",
    "    # save progress to disc at every iteration\n",
    "    dir=os.path.join(BACKPROJECTED_SCORES_FOLDER, \"iteration_\" + str(ns.subset_iterations_count))\n",
    "    os.mkdir(dir)\n",
    "    # save\n",
    "    ns.save(dir)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individual images visual integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 250, 1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_batch_size = 1000\n",
    "\n",
    "# new random subsets every time\n",
    "pat = Pattern_Generator(\n",
    "    subset_batch_size,  \n",
    "    activation_shapes,\n",
    "    frac=0.01\n",
    "    )\n",
    "\n",
    "# layer x image x subset\n",
    "integration = np.full([num_layers,num_images,subset_batch_size], np.nan)\n",
    "integration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate image set\n",
    "for img_id, (img_full, img_v1, img_v2) in enumerate(iter(dataset)):    \n",
    "    act_full = Activation_Pattern(activation_extractor(img_full))\n",
    "    act_v1   = Activation_Pattern(activation_extractor(img_v1))\n",
    "    act_v2   = Activation_Pattern(activation_extractor(img_v2))\n",
    "    act_avg  = Activation_Pattern.average(act_v1, act_v2)\n",
    "\n",
    "    # iterate node subsets\n",
    "    for subset_num in range(subset_batch_size):\n",
    "        subset_mask = pat.get_subset_pattern(subset_num)\n",
    "        \n",
    "        subset_act_full = act_full[subset_mask]\n",
    "        subset_act_avg  = act_avg[subset_mask]\n",
    "\n",
    "        # calculate integration and store it\n",
    "        subset_integration = calculate_integration_coeff(subset_act_full, subset_act_avg)\n",
    "        integration[:,img_id, subset_num] = subset_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./individual_image_analysis/taskonomy9.npy', 'wb') as file:\n",
    "    np.save(file, integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./individual_image_analysis/taskonomy18.npy', 'rb') as file:\n",
    "    btegration = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12250000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(btegration.shape).cumprod()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(btegration == integration).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 250, 1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btegration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat.num_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map back scores for one image\n",
    "img_idx = 0\n",
    "image_scores = btegration[:,img_idx, :]\n",
    "\n",
    "ns_img = NetworkScorer(activation_shapes)\n",
    "ns_img.map_back_scores(image_scores, pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -7.2637,  -6.5449,  -2.1384,  ...,  -9.4562, -10.1258,  -9.4717])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernames = list(ns_img.scores.keys())\n",
    "ns_img.scores[layernames[35]].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUdElEQVR4nO3db4xd9Z3f8fcndsqiLFCCDTg2rd3iSsGoa4TtIkWt0npbvFFVSAuS8yBYWiQnlEi70j4o7D7YdCNL0CqgkhYqpyAMShYsdlOsbWjXhW2jlbzGQ0IhhnWZxBQMBptAiJMWt3a+fXB/g6+H65k745m51zPvl3R1z/2e3+/M7x5fz2fO35uqQpKkjw16AJKk4WAgSJIAA0GS1BgIkiTAQJAkNYsHPYDpWrJkSa1cuXLQw5Ckc8pzzz33TlUt7TXvnA2ElStXMjIyMuhhSNI5Jcn/OtM8dxlJkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSgHP4SmVJw2XfW/v6arf+8vWzPBJNl4EgaUL9/qLXuc9dRpIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNd66QppnvKeQpstAkBYo71Gk8dxlJEkCDARJUjNpICT5lSTPJvkfSfYn+Zet/skku5O80p4v7upzZ5LRJAeSXN9VvzbJi23efUnS6uclebzV9yZZOfNvVZI0kX62EI4D/6Cqfg1YC2xKch1wB/B0Va0Gnm6vSXIVsBlYA2wC7k+yqC3rAWArsLo9NrX6rcB7VXUlcC9w9wy8N0nSFEwaCNXx8/by4+1RwA3AjlbfAdzYpm8AHquq41V1EBgFNiRZBlxYVXuqqoBHxvUZW9YTwMaxrQdJ0tzo6xhCkkVJngeOALurai9wWVUdBmjPl7bmy4HXu7ofarXlbXp8/bQ+VXUCeB+4pMc4tiYZSTJy9OjR/t6hJKkvfQVCVZ2sqrXACjp/7V89QfNef9nXBPWJ+owfx/aqWldV65YuXTrZsCVJUzCls4yq6qfAf6Oz7//tthuI9nykNTsEXNHVbQXwZquv6FE/rU+SxcBFwLtTGZsk6exMemFakqXA/6uqnyY5H/h1Ogd9dwFbgLva85Otyy7g20nuAT5F5+Dxs1V1MsmxdkB6L3AL8I2uPluAPcBNwDPtOIOkecYrqYdXP1cqLwN2tDOFPgbsrKo/SbIH2JnkVuA14GaAqtqfZCfwEnACuL2qTrZl3QY8DJwPPNUeAA8CjyYZpbNlsHkm3pwkqX+TBkJVvQBc06P+E2DjGfpsA7b1qI8AHzn+UFUf0AJFkjQYXqksSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNZMGQpIrkvxZkpeT7E/yW63+1SRvJHm+PT7X1efOJKNJDiS5vqt+bZIX27z7kqTVz0vyeKvvTbJy5t+qJGki/WwhnAB+p6o+DVwH3J7kqjbv3qpa2x7fBWjzNgNrgE3A/UkWtfYPAFuB1e2xqdVvBd6rqiuBe4G7z/6tSZKmYtJAqKrDVfX9Nn0MeBlYPkGXG4DHqup4VR0ERoENSZYBF1bVnqoq4BHgxq4+O9r0E8DGsa0HSdLcmNIxhLYr5xpgbyt9JckLSR5KcnGrLQde7+p2qNWWt+nx9dP6VNUJ4H3gkh4/f2uSkSQjR48encrQJUmT6DsQkvwq8EfAb1fVz+js/vmbwFrgMPD1saY9utcE9Yn6nF6o2l5V66pq3dKlS/sduiSpD30FQpKP0wmDb1XVHwNU1dtVdbKqfgl8E9jQmh8CrujqvgJ4s9VX9Kif1ifJYuAi4N3pvCFJ0vT0c5ZRgAeBl6vqnq76sq5mnwd+2KZ3AZvbmUOr6Bw8fraqDgPHklzXlnkL8GRXny1t+ibgmXacQZI0Rxb30eYzwBeBF5M832q/C3whyVo6u3ZeBb4EUFX7k+wEXqJzhtLtVXWy9bsNeBg4H3iqPaATOI8mGaWzZbD57N6WJGmqJg2Eqvpzeu/j/+4EfbYB23rUR4Cre9Q/AG6ebCySpNnjlcqSJMBAkCQ1BoIkCejvoLKkIbDvrX2DHoLmOQNB0lDqNwDXX75+lkeycLjLSJIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBPQRCEmuSPJnSV5Osj/Jb7X6J5PsTvJKe764q8+dSUaTHEhyfVf92iQvtnn3JUmrn5fk8Vbfm2TlzL9VSdJE+tlCOAH8TlV9GrgOuD3JVcAdwNNVtRp4ur2mzdsMrAE2AfcnWdSW9QCwFVjdHpta/Vbgvaq6ErgXuHsG3pskaQomDYSqOlxV32/Tx4CXgeXADcCO1mwHcGObvgF4rKqOV9VBYBTYkGQZcGFV7amqAh4Z12dsWU8AG8e2HiRJc2NKxxDarpxrgL3AZVV1GDqhAVzami0HXu/qdqjVlrfp8fXT+lTVCeB94JIeP39rkpEkI0ePHp3K0CVJk+g7EJL8KvBHwG9X1c8matqjVhPUJ+pzeqFqe1Wtq6p1S5cunWzIkqQp6CsQknycThh8q6r+uJXfbruBaM9HWv0QcEVX9xXAm62+okf9tD5JFgMXAe9O9c1Ikqavn7OMAjwIvFxV93TN2gVsadNbgCe76pvbmUOr6Bw8frbtVjqW5Lq2zFvG9Rlb1k3AM+04gyRpjizuo81ngC8CLyZ5vtV+F7gL2JnkVuA14GaAqtqfZCfwEp0zlG6vqpOt323Aw8D5wFPtAZ3AeTTJKJ0tg81n+b4kSVM0aSBU1Z/Tex8/wMYz9NkGbOtRHwGu7lH/gBYokqTB8EplSRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJQH9fkCNpgVn0g5en1P7kNZ+epZFoLrmFIEkC3EKQFoxef/UffOcXU1rGqiWfmKnhzJh9b+3rq936y9fP8kjOfQaCNI/sf+P9M867YIq//LXwuMtIkgQYCJKkxkCQJAEGgiSpmTQQkjyU5EiSH3bVvprkjSTPt8fnuubdmWQ0yYEk13fVr03yYpt3X5K0+nlJHm/1vUlWzuxblCT1o58thIeBTT3q91bV2vb4LkCSq4DNwJrW5/4ki1r7B4CtwOr2GFvmrcB7VXUlcC9w9zTfiyTpLEwaCFX1PeDdPpd3A/BYVR2vqoPAKLAhyTLgwqraU1UFPALc2NVnR5t+Atg4tvUgSZo7Z3MM4StJXmi7lC5uteXA611tDrXa8jY9vn5an6o6AbwPXNLrBybZmmQkycjRo0fPYuiSpPGme2HaA8DXgGrPXwd+E+j1l31NUGeSeacXq7YD2wHWrVvXs400n+z50U8+nD7w09MvOrvgpVc+0v6CWR7PGa9s3j3Ss9zrymbvezS8prWFUFVvV9XJqvol8E1gQ5t1CLiiq+kK4M1WX9GjflqfJIuBi+h/F5UkaYZMKxDaMYExnwfGzkDaBWxuZw6tonPw+NmqOgwcS3JdOz5wC/BkV58tbfom4Jl2nEGSNIcm3WWU5A+BzwJLkhwCfh/4bJK1dHbtvAp8CaCq9ifZCbwEnABur6qTbVG30Tlj6XzgqfYAeBB4NMkonS2DzTPxxiRJUzNpIFTVF3qUH5yg/TZgW4/6CHB1j/oHwM2TjUOSNLu8UlmSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpGa6t7+WNA3dt7PuZfEL3z/9ddf0BT8fnYURSae4hSBJAgwESVLjLiNJs6bXN6wde+P9Hi1PWbP8otkajibhFoIkCXALQdIc6/Vd0N0WHTn9e5j9Dua54xaCJAlwC0EauAM//cGH055aqkFyC0GSBBgIkqTGQJAkAQaCJKmZNBCSPJTkSJIfdtU+mWR3klfa88Vd8+5MMprkQJLru+rXJnmxzbsvSVr9vCSPt/reJCtn9i1KkvrRzxbCw8CmcbU7gKerajXwdHtNkquAzcCa1uf+JItanweArcDq9hhb5q3Ae1V1JXAvcPd034wkafomDYSq+h7w7rjyDcCONr0DuLGr/lhVHa+qg8AosCHJMuDCqtpTVQU8Mq7P2LKeADaObT1IkubOdI8hXFZVhwHa86Wtvhx4vavdoVZb3qbH10/rU1UngPeBS3r90CRbk4wkGTl69Og0hy5J6mWmDyr3+su+JqhP1OejxartVbWuqtYtXbp0mkOUJPUy3SuV306yrKoOt91BR1r9EHBFV7sVwJutvqJHvbvPoSSLgYv46C4qSTor+97a11e79Zevn+WRDK/pBsIuYAtwV3t+sqv+7ST3AJ+ic/D42ao6meRYkuuAvcAtwDfGLWsPcBPwTDvOIA21yb79TDrXTBoISf4Q+CywJMkh4PfpBMHOJLcCrwE3A1TV/iQ7gZeAE8DtVXWyLeo2OmcsnQ881R4ADwKPJhmls2WweUbemTQExn8lZi/ev0jDYtJAqKovnGHWxjO03wZs61EfAa7uUf+AFiiSpMHxSmVJEmAgSJIaA0GSBBgIkqTGb0yTNNQW/eDlvtv6/ctnx0CQNFQOvvOLKbVfteQTszSShcddRpIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1HhhmtT084U33d9v4H8ezTduIUiSAANBktQYCJIkwECQJDUGgiQJMBAkSY1nzkmz5LWfjw56CNKUnNUWQpJXk7yY5PkkI632ySS7k7zSni/uan9nktEkB5Jc31W/ti1nNMl9SXI245IkTd1M7DL6+1W1tqrWtdd3AE9X1Wrg6faaJFcBm4E1wCbg/iSLWp8HgK3A6vbYNAPjkiRNwWwcQ7gB2NGmdwA3dtUfq6rjVXUQGAU2JFkGXFhVe6qqgEe6+kiS5sjZBkIBf5rkuSRbW+2yqjoM0J4vbfXlwOtdfQ+12vI2Pb7+EUm2JhlJMnL06NGzHLokqdvZHlT+TFW9meRSYHeSv5ygba/jAjVB/aPFqu3AdoB169b1bCNpYTn4zi9Ovdg9Mmn7VUs+8eH0yWs+/ZH5+97a1/fPXn/5+r7bngvOaguhqt5sz0eA7wAbgLfbbiDa85HW/BBwRVf3FcCbrb6iR12SNIemvYWQ5BPAx6rqWJv+R8AfALuALcBd7fnJ1mUX8O0k9wCfonPw+NmqOpnkWJLrgL3ALcA3pjsuaUw/dy+VdMrZ7DK6DPhOO0N0MfDtqvrPSfYBO5PcCrwG3AxQVfuT7AReAk4At1fVybas24CHgfOBp9pDmhPdt7SWFrJpB0JV/Rj4tR71nwAbz9BnG7CtR30EuHq6Y5EknT2vVJY0Jb9y7NUZWc4HF6yckeVo5ngvI0kS4BaCpHFmagtA5x4DQdJA9BM87laaW+4ykiQBbiFIU+ZtrTVfGQjSAuLxAU3EQJA0tDzOMLcMBJ0z+r0VxdiVx364panxoLIkCfCPKEkLTPftso+98f6k7dcsv2g2hzNUDARJC9YFL70yaZtFRzrfn9DruxPmGwNBmic8g0hny0CQdE6bLAg9C6l/BoIkTVO/X7d5rnzVpoGggRm2bzQb5iuQ3R2kuWAg6Jzgt5pJs8/rECRJgFsIkuY5b3/RPwNBGgIeI9AwMBA0Y6ZykHjxC9+fsw/fMB8s1vD78Mrm3SN9tV+15Ny9kM1AkGaZf/3rXGEgSFrwZvs4w7lyvcLQBEKSTcC/ARYB/6Gq7hrwkBa06VwjMNenhg7DriD/+td8MhSBkGQR8O+AfwgcAvYl2VVVLw12ZPPHufALfsww/KIHf9nrdP1uRUznmMOwHG8YikAANgCjVfVjgCSPATcACyYQpnvVbr+/tIfhH3ouf9H7y1yDMJ37Kh185xcfhsdr9Bci/+yLt011aH0Zht8TAMuB17teHwL+zvhGSbYCW9vLnyc5MAdjm21LgHcGPYgh4vo4xXVxiuui2y3//GzWx18/04xhCYT0qNVHClXbge2zP5y5k2SkqtYNehzDwvVxiuviFNfF6WZrfQzLrSsOAVd0vV4BvDmgsUjSgjQsgbAPWJ1kVZK/AmwGdg14TJK0oAzFLqOqOpHkK8B/oXPa6UNVtX/Aw5or82oX2AxwfZziujjFdXG6WVkfqfrIrnpJ0gI0LLuMJEkDZiBIkgADYWCS/Oskf5nkhSTfSfJXu+bdmWQ0yYEk1w9ynHMhyc1J9if5ZZJ1XfWVSf5Pkufb498Pcpxz5Uzro81bUJ+Nbkm+muSNrs/D5wY9prmWZFP7tx9NcsdML99AGJzdwNVV9beB/wncCZDkKjpnWa0BNgH3t1t7zGc/BP4p8L0e835UVWvb48tzPK5B6bk+FuhnY7x7uz4P3x30YOZS1y1+fgO4CvhC+0zMGANhQKrqT6vqRHv5F3SuvYDOLTseq6rjVXUQGKVza495q6perqr5cNX5jJhgfSy4z4ZO8+Etfqrq/wJjt/iZMQbCcPhN4Kk23es2HsvnfETDY1WSHyT570n+7qAHM2B+NuArbTfrQ0kuHvRg5tis//sPxXUI81WS/wpc3mPW71XVk63N7wEngG+NdevR/pw/N7ifddHDYeCvVdVPklwL/Mcka6rqZ7M20DkyzfUxLz8b3SZaL8ADwNfovOevAV+n88fUQjHr//4Gwiyqql+faH6SLcA/BjbWqQtC5uVtPCZbF2focxw43qafS/Ij4G9Bn7eEHGLTWR/M089Gt37XS5JvAn8yy8MZNrP+7+8uowFpXwj0L4B/UlX/u2vWLmBzkvOSrAJWA88OYoyDlmTp2EHTJH+Dzrr48WBHNVAL+rORZFnXy8/TOfi+kMz6LX7cQhicfwucB+xOAvAXVfXlqtqfZCed74I4AdxeVScHOM5Zl+TzwDeApcB/SvJ8VV0P/D3gD5KcAE4CX66qdwc41DlxpvWxED8b4/yrJGvp7CZ5FfjSYIczt+biFj/eukKSBLjLSJLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVLz/wEv0Fe/CUS88AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [10, 20, 30, 40]:\n",
    "    plt.hist(ns_img.scores[list(ns_img.scores.keys())[i]].flatten(), bins=25, alpha = .25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
